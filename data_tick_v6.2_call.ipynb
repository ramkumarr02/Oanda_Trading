{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import winsound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from multiprocessing import  Pool\n",
    "import time\n",
    "import imblearn\n",
    "\n",
    "import math, collections\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(y_axis):\n",
    "    global data\n",
    "    ma_len = len(y_axis)\n",
    "    \n",
    "    x_axis = []\n",
    "    for i in range(ma_len):\n",
    "        x_axis.append(1 + ((i+1) * 0.0001 * 0.1))\n",
    "    \n",
    "    slope_tick, intercept, _, _, _ = linregress(x_axis, y_axis)\n",
    "    slope_tick = math.degrees(math.atan(slope_tick))\n",
    "    \n",
    "    return(slope_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_ticks(df, number_of_ticks):   \n",
    "    global data\n",
    "    \n",
    "    df['tick'] = (df['Bid'] + df['Ask'])/2\n",
    "    df['spread'] = df['Ask'] - df['Bid']\n",
    "    df = df[['tick', 'spread']]\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    tick_avg = []\n",
    "    spread_avg = []\n",
    "    tick_sd = []\n",
    "    tick_act = []\n",
    "    \n",
    "    for i in tqdm(range(0,len(df),number_of_ticks)):\n",
    "        tick_list = list(df['tick'][i:i+number_of_ticks])\n",
    "        spread_list = list(df['spread'][i:i+number_of_ticks])\n",
    "        #print(len(tick_list))\n",
    "        tick_act.append(tick_list[-1])              \n",
    "        temp = list(pd.DataFrame(tick_list).ewm(span=len(tick_list)).mean()[0])[len(tick_list) - 1]\n",
    "        tick_avg.append(temp)\n",
    "\n",
    "        spread_avg.append(np.mean(spread_list))\n",
    "        tick_sd.append(np.std(tick_list))\n",
    "        \n",
    "    temp_df['tick_act'] = tick_act      \n",
    "    temp_df['tick_avg'] = tick_avg  \n",
    "    temp_df['spread_avg'] = spread_avg  \n",
    "    temp_df['tick_sd'] = tick_sd  \n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_sma():\n",
    "    global data    \n",
    "    data['ssma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_sma():\n",
    "    global data\n",
    "    \n",
    "    data['ssma_list'].popleft()\n",
    "    data['ssma_list'].append(val)\n",
    "    data['sema'] = list(pd.DataFrame(list(data['ssma_list'])).ewm(span=data['sma_len']).mean()[0])[data['sma_len'] - 1]\n",
    "    \n",
    "    if len(data['sema_ready']) < 2:\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['sema_ready']) > 1:\n",
    "        data['sema_ready'].popleft()\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = data['sema_ready'][-1] - data['sema_ready'][len(data['sema_ready'])-2]\n",
    "    \n",
    "    return()\n",
    "\n",
    "def before_lma():\n",
    "    global data    \n",
    "    data['lsma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_lma():\n",
    "    global data\n",
    "    \n",
    "    data['lsma_list'].popleft()\n",
    "    data['lsma_list'].append(val)\n",
    "    data['lema'] = list(pd.DataFrame(list(data['lsma_list'])).ewm(span=data['lma_len']).mean()[0])[data['lma_len'] - 1]\n",
    "    \n",
    "    if len(data['lema_ready']) < 2:\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['lema_ready']) > 1:\n",
    "        data['lema_ready'].popleft()\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = data['lema_ready'][-1] - data['lema_ready'][len(data['lema_ready'])-2]\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_ma(ma_list):\n",
    "    global data\n",
    "    ma_len = len(ma_list)\n",
    "    sema_val = list(pd.DataFrame(ma_list).ewm(span=ma_len).mean()[0])[ma_len - 1]    \n",
    "    return(sema_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_custom_value_counts(df, target_column, filter_column = None, filter_value = None):    \n",
    "    if filter_column is None and filter_value is None:\n",
    "        print(f'target_column : {target_column}')\n",
    "        g= df[target_column]\n",
    "        print(pd.concat([g.value_counts(), g.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage')))\n",
    "    else:\n",
    "        print(f'{filter_column} : {filter_value}')\n",
    "        g= df.loc[df[filter_column] == filter_value, target_column]\n",
    "        print(pd.concat([g.value_counts(), g.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage')))\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_prep(year):\n",
    "    global data\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "    \n",
    "    diff_col = 'sema'\n",
    "    #diff_col = 'tick_avg'\n",
    "\n",
    "    source_file_path = f'data/yearly_tick_data/{year}.csv'\n",
    "    path, file_name = os.path.split(source_file_path)\n",
    "\n",
    "    target_file_name = 'tab_'+file_name\n",
    "    target_file_path = os.path.join(path, target_file_name)\n",
    "\n",
    "    chunk_file_name = 'chunk_'+file_name\n",
    "    chunk_file_path = os.path.join(path, chunk_file_name)\n",
    "\n",
    "    print(f'source_file_path : {source_file_path}')\n",
    "    print(f'chunk_file_path : {chunk_file_path}')\n",
    "    print(f'target_file_path : {target_file_path}')\n",
    "\n",
    "    if data['input_rows'] is None:\n",
    "        df = pd.read_csv(source_file_path)\n",
    "    else:\n",
    "        df = pd.read_csv(source_file_path, nrows=data['input_rows'])\n",
    "    print(f'Total input recs : {len(df)}')\n",
    "    print(\"Data manipulation...\")\n",
    "    df = chunk_ticks(df, data['number_of_ticks'])\n",
    "    df.to_csv(chunk_file_path, index = False)\n",
    "    print(f'Records : {len(df)}')\n",
    "\n",
    "    df = pd.read_csv(chunk_file_path)\n",
    "\n",
    "    data['rs_max'] = 1e6\n",
    "\n",
    "    data['ssma_list'] = collections.deque([])\n",
    "    data['lsma_list'] = collections.deque([])\n",
    "    data['sema_ready'] = collections.deque([])\n",
    "    data['lema_ready'] = collections.deque([])\n",
    "    df['sema'] = ''\n",
    "    df['lema'] = ''\n",
    "    df['sema_diff'] = ''\n",
    "    df['lema_diff'] = ''\n",
    "\n",
    "\n",
    "    # RSI -----------------------------\n",
    "    df['diff'] = df['tick_avg'].diff()\n",
    "    df['gain'] = 0\n",
    "    df['loss'] = 0\n",
    "    df['gain'].loc[df['diff'] > 0] = abs(df['diff'])\n",
    "    df['loss'].loc[df['diff'] < 0] = abs(df['diff'])\n",
    "    df['avg_gain'] = df['gain'].rolling(window=data['rsi_window']).mean()\n",
    "    df['avg_loss'] = df['loss'].rolling(window=data['rsi_window']).mean()\n",
    "    df['rs'] = df['avg_gain']/df['avg_loss']\n",
    "    df['rs'] = df['rs'].where(df['rs'] <= data['rs_max'], data['rs_max']) \n",
    "    df['rsi'] = 100 - (100 / (df['rs'] + 1))\n",
    "\n",
    "    # Simple Moving Averages ------------------\n",
    "    df['ssma'] = df['tick_avg'].rolling(window=data['sma_len']).mean()\n",
    "    df['ssma_diff'] = df['ssma'].diff()\n",
    "    df['lsma'] = df['tick_avg'].rolling(window=data['lma_len']).mean()\n",
    "    df['lsma_diff'] = df['lsma'].diff()\n",
    "    df['sma_diff'] = df['ssma'] - df['lsma']\n",
    "\n",
    "    df['max_tick'] = df['tick_avg'].rolling(window=data['sma_len']).max()\n",
    "    df['min_tick'] = df['tick_avg'].rolling(window=data['sma_len']).min()\n",
    "\n",
    "    df['max_gap'] = df['max_tick'] -  df['tick_avg']\n",
    "    df['min_gap'] = df['min_tick'] - df['tick_avg']\n",
    "\n",
    "    print(\"Emas creation...\")\n",
    "    # Emas ----------------\n",
    "    df['sema'] = df['tick_avg'].rolling(window=data['sma_len']).progress_apply(roll_ma)\n",
    "    df['lema'] = df['tick_avg'].rolling(window=data['lma_len']).progress_apply(roll_ma)\n",
    "\n",
    "    df['sema_diff'] = df['sema'].diff()\n",
    "    df['lema_diff'] = df['lema'].diff()\n",
    "\n",
    "    df['ema_diff'] = df['sema'] - df['lema']\n",
    "\n",
    "    print(\"slope creation...\")\n",
    "    # Slopes -----------------------------\n",
    "    df['small_sema_slope'] = df['sema'].rolling(window=data['sma_len']).progress_apply(get_slope)\n",
    "    df['long_sema_slope'] = df['sema'].rolling(window=data['lma_len']).progress_apply(get_slope)\n",
    "\n",
    "    df['slope_diff'] = df['small_sema_slope'] - df['long_sema_slope']\n",
    "\n",
    "    print('Direction identification...')\n",
    "    df = df.round(5)\n",
    "\n",
    "    # Direction -------------------------\n",
    "    df['direction'] = 'same'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    # Remove NaNs ------------------------\n",
    "    del df['gain']\n",
    "    del df['loss']\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f'Total records : {len(df)}')\n",
    "\n",
    "    df.to_csv(target_file_path, index = False)\n",
    "    winsound.PlaySound('C:\\\\Windows\\\\Media\\\\tada.wav', winsound.SND_ASYNC)\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'direction')    \n",
    "    \n",
    "    print('Avg Direction -------------------------')\n",
    "    diff_col = 'tick_avg'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'same')    \n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'increase')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'decrease')\n",
    "\n",
    "    print('\\n')\n",
    "    df['tick_act_direction'] = df['act_direction']\n",
    "    del df['act_direction']    \n",
    "\n",
    "    print('Act Direction -------------------------')\n",
    "    diff_col = 'tick_act'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'same')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'increase')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'decrease')\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    #del df['act_direction']\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['number_of_ticks']   = 300\n",
    "data['rsi_window']        = 14\n",
    "data['sma_len']           = 5\n",
    "data['lma_len']           = 10\n",
    "data['pip_diff']          = 0.00012\n",
    "\n",
    "data['input_rows']        = 5_000_000\n",
    "data['input_rows']        = None\n",
    "\n",
    "train_files = [2019]\n",
    "#train_files = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------2019--------------------------------------\n",
      "source_file_path : data/yearly_tick_data/2019.csv\n",
      "chunk_file_path : data/yearly_tick_data\\chunk_2019.csv\n",
      "target_file_path : data/yearly_tick_data\\tab_2019.csv\n",
      "Total input recs : 29186310\n",
      "Data manipulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 97288/97288 [02:07<00:00, 765.10it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records : 97288\n",
      "Emas creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97284it [01:31, 1058.14it/s]\n",
      "97279it [01:33, 1043.78it/s]\n",
      "680it [00:00, 3377.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97280it [00:28, 3444.22it/s]\n",
      "97275it [00:28, 3414.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction identification...\n",
      "Total records : 97275\n",
      "target_column : direction\n",
      "          counts  percentage\n",
      "same       83200   85.530712\n",
      "decrease    7307    7.511694\n",
      "increase    6768    6.957594\n",
      "=======================\n",
      "Avg Direction -------------------------\n",
      "direction : same\n",
      "          counts  percentage\n",
      "same       57299   68.868990\n",
      "increase   13103   15.748798\n",
      "decrease   12798   15.382212\n",
      "=======================\n",
      "direction : increase\n",
      "          counts  percentage\n",
      "increase    5362   79.225768\n",
      "same        1330   19.651300\n",
      "decrease      76    1.122931\n",
      "=======================\n",
      "direction : decrease\n",
      "          counts  percentage\n",
      "decrease    5761   78.842206\n",
      "same        1449   19.830300\n",
      "increase      97    1.327494\n",
      "=======================\n",
      "\n",
      "\n",
      "Act Direction -------------------------\n",
      "direction : same\n",
      "          counts  percentage\n",
      "same       48155   57.878606\n",
      "increase   17737   21.318510\n",
      "decrease   17308   20.802885\n",
      "=======================\n",
      "direction : increase\n",
      "          counts  percentage\n",
      "increase    4156   61.406619\n",
      "same        2172   32.092199\n",
      "decrease     440    6.501182\n",
      "=======================\n",
      "direction : decrease\n",
      "          counts  percentage\n",
      "decrease    4531   62.009032\n",
      "same        2279   31.189271\n",
      "increase     497    6.801697\n",
      "=======================\n",
      "\n",
      "\n",
      "-----------------------------------2019--------------------------------------\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in train_files:\n",
    "    df = run_data_prep(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv('temp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
