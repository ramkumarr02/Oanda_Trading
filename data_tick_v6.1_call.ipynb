{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import winsound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from multiprocessing import  Pool\n",
    "import time\n",
    "import imblearn\n",
    "\n",
    "import math, collections\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(y_axis):\n",
    "    global data\n",
    "    ma_len = len(y_axis)\n",
    "    \n",
    "    x_axis = []\n",
    "    for i in range(ma_len):\n",
    "        x_axis.append(1 + ((i+1) * 0.0001 * 0.1))\n",
    "    \n",
    "    slope_tick, intercept, _, _, _ = linregress(x_axis, y_axis)\n",
    "    slope_tick = math.degrees(math.atan(slope_tick))\n",
    "    \n",
    "    return(slope_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_ticks(df, number_of_ticks):   \n",
    "    global data\n",
    "    \n",
    "    df['tick'] = (df['Bid'] + df['Ask'])/2\n",
    "    df['spread'] = df['Ask'] - df['Bid']\n",
    "    df = df[['tick', 'spread']]\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    tick_avg = []\n",
    "    spread_avg = []\n",
    "    tick_sd = []\n",
    "    tick_act = []\n",
    "    \n",
    "    for i in tqdm(range(0,len(df),number_of_ticks)):\n",
    "        tick_list = list(df['tick'][i:i+number_of_ticks])\n",
    "        spread_list = list(df['spread'][i:i+number_of_ticks])\n",
    "        #print(len(tick_list))\n",
    "        tick_act.append(tick_list[-1])              \n",
    "        temp = list(pd.DataFrame(tick_list).ewm(span=len(tick_list)).mean()[0])[len(tick_list) - 1]\n",
    "        tick_avg.append(temp)\n",
    "\n",
    "        spread_avg.append(np.mean(spread_list))\n",
    "        tick_sd.append(np.std(tick_list))\n",
    "        \n",
    "    temp_df['tick_act'] = tick_act      \n",
    "    temp_df['tick_avg'] = tick_avg  \n",
    "    temp_df['spread_avg'] = spread_avg  \n",
    "    temp_df['tick_sd'] = tick_sd  \n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_sma():\n",
    "    global data    \n",
    "    data['ssma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_sma():\n",
    "    global data\n",
    "    \n",
    "    data['ssma_list'].popleft()\n",
    "    data['ssma_list'].append(val)\n",
    "    data['sema'] = list(pd.DataFrame(list(data['ssma_list'])).ewm(span=data['sma_len']).mean()[0])[data['sma_len'] - 1]\n",
    "    \n",
    "    if len(data['sema_ready']) < 2:\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['sema_ready']) > 1:\n",
    "        data['sema_ready'].popleft()\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = data['sema_ready'][-1] - data['sema_ready'][len(data['sema_ready'])-2]\n",
    "    \n",
    "    return()\n",
    "\n",
    "def before_lma():\n",
    "    global data    \n",
    "    data['lsma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_lma():\n",
    "    global data\n",
    "    \n",
    "    data['lsma_list'].popleft()\n",
    "    data['lsma_list'].append(val)\n",
    "    data['lema'] = list(pd.DataFrame(list(data['lsma_list'])).ewm(span=data['lma_len']).mean()[0])[data['lma_len'] - 1]\n",
    "    \n",
    "    if len(data['lema_ready']) < 2:\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['lema_ready']) > 1:\n",
    "        data['lema_ready'].popleft()\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = data['lema_ready'][-1] - data['lema_ready'][len(data['lema_ready'])-2]\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_ma(ma_list):\n",
    "    global data\n",
    "    ma_len = len(ma_list)\n",
    "    sema_val = list(pd.DataFrame(ma_list).ewm(span=ma_len).mean()[0])[ma_len - 1]    \n",
    "    return(sema_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_prep(year):\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "\n",
    "    data = {}\n",
    "    data['number_of_ticks'] = 300\n",
    "    data['rsi_window'] = 14\n",
    "    data['sma_len'] = 5\n",
    "    data['lma_len'] = 14\n",
    "\n",
    "    diff_col = 'sema'\n",
    "    #diff_col = 'tick_avg'\n",
    "\n",
    "    data['pip_diff'] = 0.0002\n",
    "\n",
    "    source_file_path = f'data/yearly_tick_data/{year}.csv'\n",
    "    path, file_name = os.path.split(source_file_path)\n",
    "\n",
    "    target_file_name = 'tab_'+file_name\n",
    "    target_file_path = os.path.join(path, target_file_name)\n",
    "\n",
    "    chunk_file_name = 'chunk_'+file_name\n",
    "    chunk_file_path = os.path.join(path, chunk_file_name)\n",
    "\n",
    "    print(f'source_file_path : {source_file_path}')\n",
    "    print(f'chunk_file_path : {chunk_file_path}')\n",
    "    print(f'target_file_path : {target_file_path}')\n",
    "\n",
    "    #df = pd.read_csv(source_file_path, nrows=10000000)\n",
    "    df = pd.read_csv(source_file_path)\n",
    "\n",
    "    print(\"Data manipulation...\")\n",
    "    df = chunk_ticks(df, data['number_of_ticks'])\n",
    "    df.to_csv(chunk_file_path, index = False)\n",
    "    print(f'Records : {len(df)}')\n",
    "\n",
    "    df = pd.read_csv(chunk_file_path)\n",
    "\n",
    "    data['rs_max'] = 1e6\n",
    "\n",
    "    data['ssma_list'] = collections.deque([])\n",
    "    data['lsma_list'] = collections.deque([])\n",
    "    data['sema_ready'] = collections.deque([])\n",
    "    data['lema_ready'] = collections.deque([])\n",
    "    df['sema'] = ''\n",
    "    df['lema'] = ''\n",
    "    df['sema_diff'] = ''\n",
    "    df['lema_diff'] = ''\n",
    "\n",
    "\n",
    "    # RSI -----------------------------\n",
    "    df['diff'] = df['tick_avg'].diff()\n",
    "    df['gain'] = 0\n",
    "    df['loss'] = 0\n",
    "    df['gain'].loc[df['diff'] > 0] = abs(df['diff'])\n",
    "    df['loss'].loc[df['diff'] < 0] = abs(df['diff'])\n",
    "    df['avg_gain'] = df['gain'].rolling(window=data['rsi_window']).mean()\n",
    "    df['avg_loss'] = df['loss'].rolling(window=data['rsi_window']).mean()\n",
    "    df['rs'] = df['avg_gain']/df['avg_loss']\n",
    "    df['rs'] = df['rs'].where(df['rs'] <= data['rs_max'], data['rs_max']) \n",
    "    df['rsi'] = 100 - (100 / (df['rs'] + 1))\n",
    "\n",
    "    # Simple Moving Averages ------------------\n",
    "    df['ssma'] = df['tick_avg'].rolling(window=data['sma_len']).mean()\n",
    "    df['ssma_diff'] = df['ssma'].diff()\n",
    "    df['lsma'] = df['tick_avg'].rolling(window=data['lma_len']).mean()\n",
    "    df['lsma_diff'] = df['lsma'].diff()\n",
    "    df['sma_diff'] = df['ssma'] - df['lsma']\n",
    "\n",
    "    df['max_tick'] = df['tick_avg'].rolling(window=data['sma_len']).max()\n",
    "    df['min_tick'] = df['tick_avg'].rolling(window=data['sma_len']).min()\n",
    "\n",
    "    df['max_gap'] = df['max_tick'] -  df['tick_avg']\n",
    "    df['min_gap'] = df['min_tick'] - df['tick_avg']\n",
    "\n",
    "    print(\"Emas creation...\")\n",
    "    # Emas ----------------\n",
    "    df['sema'] = df['tick_avg'].rolling(window=data['sma_len']).progress_apply(roll_ma)\n",
    "    df['lema'] = df['tick_avg'].rolling(window=data['lma_len']).progress_apply(roll_ma)\n",
    "\n",
    "    df['sema_diff'] = df['sema'].diff()\n",
    "    df['lema_diff'] = df['lema'].diff()\n",
    "\n",
    "    df['ema_diff'] = df['sema'] - df['lema']\n",
    "\n",
    "    print(\"slope creation...\")\n",
    "    # Slopes -----------------------------\n",
    "    df['small_sema_slope'] = df['sema'].rolling(window=data['sma_len']).progress_apply(get_slope)\n",
    "    df['long_sema_slope'] = df['sema'].rolling(window=data['lma_len']).progress_apply(get_slope)\n",
    "\n",
    "    df['slope_diff'] = df['small_sema_slope'] - df['long_sema_slope']\n",
    "\n",
    "    print('Direction identification...')\n",
    "    df = df.round(5)\n",
    "\n",
    "    # Direction -------------------------\n",
    "    df['direction'] = 'same'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] > data['pip_diff']] = 'increase'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] < -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    # Remove NaNs ------------------------\n",
    "    del df['gain']\n",
    "    del df['loss']\n",
    "    #del df['tick_act']\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f'Total records : {len(df)}')\n",
    "\n",
    "    df.to_csv(target_file_path, index = False)\n",
    "    winsound.PlaySound('C:\\\\Windows\\\\Media\\\\tada.wav', winsound.SND_ASYNC)\n",
    "\n",
    "    g= df['direction']\n",
    "    print(pd.concat([g.value_counts(), g.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage')))\n",
    "\n",
    "    # Avg Direction -------------------------\n",
    "    diff_col = 'tick_avg'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] > data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] < -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print('prediction : same')\n",
    "    print(df.loc[df['direction'] == 'same', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    print('prediction : increase')\n",
    "    print(df.loc[df['direction'] == 'increase', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    print('prediction : decrease')\n",
    "    print(df.loc[df['direction'] == 'decrease', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    df['tick_avg_diff'] = round(df['tick_avg'].diff() * 10000)\n",
    "\n",
    "    print('\\n')\n",
    "    del df['act_direction']\n",
    "    del df['tick_avg_diff']\n",
    "\n",
    "    # Act Direction -------------------------\n",
    "    diff_col = 'tick_act'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] > data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] < -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print('prediction : same')\n",
    "    print(df.loc[df['direction'] == 'same', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    print('prediction : increase')\n",
    "    print(df.loc[df['direction'] == 'increase', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    print('prediction : decrease')\n",
    "    print(df.loc[df['direction'] == 'decrease', 'act_direction'].value_counts(normalize=True))\n",
    "    print('-------------')\n",
    "\n",
    "    df['tick_avg_diff'] = round(df['tick_avg'].diff() * 10000)\n",
    "\n",
    "    print('\\n')\n",
    "    del df['act_direction']\n",
    "    del df['tick_avg_diff']\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_files = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------2020--------------------------------------\n",
      "source_file_path : data/yearly_tick_data/2020.csv\n",
      "chunk_file_path : data/yearly_tick_data\\chunk_2020.csv\n",
      "target_file_path : data/yearly_tick_data\\tab_2020.csv\n",
      "Data manipulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 109213/109213 [02:22<00:00, 765.30it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records : 109213\n",
      "Emas creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109209it [01:45, 1031.82it/s]\n",
      "109200it [01:45, 1037.80it/s]\n",
      "328it [00:00, 3256.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109205it [00:32, 3373.15it/s]\n",
      "109196it [00:32, 3384.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction identification...\n",
      "Total records : 109196\n",
      "          counts  percentage\n",
      "same       95879   87.804498\n",
      "decrease    6799    6.226419\n",
      "increase    6518    5.969083\n",
      "prediction : same\n",
      "same        0.720429\n",
      "increase    0.141157\n",
      "decrease    0.138414\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "prediction : increase\n",
      "increase    0.789506\n",
      "same        0.200828\n",
      "decrease    0.009666\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "prediction : decrease\n",
      "decrease    0.791587\n",
      "same        0.202530\n",
      "increase    0.005883\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "\n",
      "\n",
      "prediction : same\n",
      "same        0.618853\n",
      "increase    0.192284\n",
      "decrease    0.188863\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "prediction : increase\n",
      "increase    0.615986\n",
      "same        0.334305\n",
      "decrease    0.049708\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "prediction : decrease\n",
      "decrease    0.633181\n",
      "same        0.314752\n",
      "increase    0.052066\n",
      "Name: act_direction, dtype: float64\n",
      "-------------\n",
      "\n",
      "\n",
      "-----------------------------------2020--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for year in train_files:\n",
    "    run_data_prep(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python36664bitab910dfda0bc43a8bf7df0c20d1c59f2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
