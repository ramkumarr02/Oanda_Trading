{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import winsound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import modin.pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from multiprocessing import  Pool\n",
    "import time\n",
    "import imblearn\n",
    "\n",
    "import math, collections\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_hour(df):    \n",
    "    \n",
    "    weekday_val = []\n",
    "    hour = []\n",
    "    \n",
    "    for i in tqdm(df['DateTime']):\n",
    "        date_val  = dt.datetime.strptime(i, '%Y%m%d %H:%M:%S.%f')\n",
    "        weekday_val.append(date_val.weekday())\n",
    "        hour.append(date_val.hour)\n",
    "\n",
    "    df['weekday'] = weekday_val\n",
    "    df['hour'] = hour\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(y_axis):\n",
    "    global data\n",
    "    ma_len = len(y_axis)\n",
    "    \n",
    "    x_axis = []\n",
    "    for i in range(ma_len):\n",
    "        x_axis.append(1 + ((i+1) * 0.0001 * 0.1))\n",
    "    \n",
    "    slope_tick, intercept, _, _, _ = linregress(x_axis, y_axis)\n",
    "    slope_tick = math.degrees(math.atan(slope_tick))\n",
    "    \n",
    "    return(slope_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_ticks(df, number_of_ticks):   \n",
    "    global data\n",
    "    \n",
    "    df['tick'] = (df['Bid'] + df['Ask'])/2\n",
    "    df['spread'] = df['Ask'] - df['Bid']\n",
    "    df = df[['weekday', 'hour','tick', 'spread']]\n",
    "    \n",
    "    temp_df = pd.DataFrame()\n",
    "    tick_avg = []\n",
    "    spread_avg = []\n",
    "    tick_sd = []\n",
    "    tick_act = []\n",
    "    candle_height = []\n",
    "    candle_max_val = []\n",
    "    candle_min_val = []\n",
    "    weekday = []\n",
    "    hour = []\n",
    "    \n",
    "    for i in tqdm(range(0,len(df),number_of_ticks)):\n",
    "        tick_list = list(df['tick'][i:i+number_of_ticks])\n",
    "        spread_list = list(df['spread'][i:i+number_of_ticks])\n",
    "        weekday_list = list(df['weekday'][i:i+number_of_ticks])\n",
    "        hour_list = list(df['hour'][i:i+number_of_ticks])\n",
    "        \n",
    "        tick_act.append(tick_list[-1])              \n",
    "        temp = list(pd.DataFrame(tick_list).ewm(span=len(tick_list)).mean()[0])[len(tick_list) - 1]\n",
    "        tick_avg.append(temp)\n",
    "\n",
    "        spread_avg.append(np.mean(spread_list))\n",
    "        tick_sd.append(np.std(tick_list))\n",
    "        candle_height.append(np.max(tick_list) - np.min(tick_list))\n",
    "        candle_max_val.append(np.max(tick_list))\n",
    "        candle_min_val.append(np.min(tick_list))\n",
    "        weekday.append(weekday_list[-1])\n",
    "        hour.append(hour_list[-1])\n",
    "        \n",
    "    temp_df['weekday']      =  weekday\n",
    "    temp_df['hour']      = hour\n",
    "    temp_df['tick_act']      = tick_act      \n",
    "    temp_df['tick_avg']      = tick_avg  \n",
    "    temp_df['spread_avg']    = spread_avg  \n",
    "    temp_df['tick_sd']       = tick_sd  \n",
    "    temp_df['candle_height'] = candle_height\n",
    "    temp_df['candle_max_val'] = candle_max_val\n",
    "    temp_df['candle_min_val'] = candle_min_val\n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_sma():\n",
    "    global data    \n",
    "    data['ssma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_sma():\n",
    "    global data\n",
    "    \n",
    "    data['ssma_list'].popleft()\n",
    "    data['ssma_list'].append(val)\n",
    "    data['sema'] = list(pd.DataFrame(list(data['ssma_list'])).ewm(span=data['sma_len']).mean()[0])[data['sma_len'] - 1]\n",
    "    \n",
    "    if len(data['sema_ready']) < 2:\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['sema_ready']) > 1:\n",
    "        data['sema_ready'].popleft()\n",
    "        data['sema_ready'].append(data['sema'])\n",
    "        data['sema_diff'] = data['sema_ready'][-1] - data['sema_ready'][len(data['sema_ready'])-2]\n",
    "    \n",
    "    return()\n",
    "\n",
    "def before_lma():\n",
    "    global data    \n",
    "    data['lsma_list'].append(val)    \n",
    "    return()\n",
    "\n",
    "def after_lma():\n",
    "    global data\n",
    "    \n",
    "    data['lsma_list'].popleft()\n",
    "    data['lsma_list'].append(val)\n",
    "    data['lema'] = list(pd.DataFrame(list(data['lsma_list'])).ewm(span=data['lma_len']).mean()[0])[data['lma_len'] - 1]\n",
    "    \n",
    "    if len(data['lema_ready']) < 2:\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = np.nan\n",
    "\n",
    "    elif len(data['lema_ready']) > 1:\n",
    "        data['lema_ready'].popleft()\n",
    "        data['lema_ready'].append(data['lema'])\n",
    "        data['lema_diff'] = data['lema_ready'][-1] - data['lema_ready'][len(data['lema_ready'])-2]\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_ma(ma_list):\n",
    "    global data\n",
    "    ma_len = len(ma_list)\n",
    "    sema_val = list(pd.DataFrame(ma_list).ewm(span=ma_len).mean()[0])[ma_len - 1]    \n",
    "    return(sema_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_custom_value_counts(df, target_column, filter_column = None, filter_value = None):    \n",
    "    if filter_column is None and filter_value is None:\n",
    "        print(f'target_column : {target_column}')\n",
    "        g= df[target_column]\n",
    "        print(pd.concat([g.value_counts(), g.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage')))\n",
    "    else:\n",
    "        print(f'{filter_column} : {filter_value}')\n",
    "        g= df.loc[df[filter_column] == filter_value, target_column]\n",
    "        print(pd.concat([g.value_counts(), g.value_counts(normalize=True).mul(100)],axis=1, keys=('counts','percentage')))\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_prep(year):\n",
    "    global data\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "    \n",
    "    diff_col = 'sema'\n",
    "    #diff_col = 'tick_avg'\n",
    "\n",
    "    source_file_path = f'data/yearly_tick_data/{year}.csv'\n",
    "    path, file_name = os.path.split(source_file_path)\n",
    "\n",
    "    target_file_name = 'tab_'+file_name\n",
    "    target_file_path = os.path.join(path, target_file_name)\n",
    "\n",
    "    chunk_file_name = 'chunk_'+file_name\n",
    "    chunk_file_path = os.path.join(path, chunk_file_name)\n",
    "\n",
    "    print(f'source_file_path : {source_file_path}')\n",
    "    print(f'chunk_file_path : {chunk_file_path}')\n",
    "    print(f'target_file_path : {target_file_path}')\n",
    "\n",
    "    if data['input_rows'] is None:\n",
    "        df = pd.read_csv(source_file_path)\n",
    "    else:\n",
    "        df = pd.read_csv(source_file_path, nrows=data['input_rows'])\n",
    "    \n",
    "    print(f'Total input recs : {len(df)}')\n",
    "    print(\"Data manipulation...\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print('Extracing weekday and hour...')\n",
    "    time.sleep(1)\n",
    "    df = get_date_hour(df)\n",
    "    \n",
    "    print('Chunking ticks...')\n",
    "    time.sleep(1)\n",
    "    df = chunk_ticks(df, data['number_of_ticks'])\n",
    "    \n",
    "    df.to_csv(chunk_file_path, index = False)\n",
    "        \n",
    "    print(f'Records : {len(df)}')\n",
    "\n",
    "    df = pd.read_csv(chunk_file_path)\n",
    "\n",
    "    data['rs_max'] = 1e6\n",
    "\n",
    "    data['ssma_list'] = collections.deque([])\n",
    "    data['lsma_list'] = collections.deque([])\n",
    "    data['sema_ready'] = collections.deque([])\n",
    "    data['lema_ready'] = collections.deque([])\n",
    "    df['sema'] = ''\n",
    "    df['lema'] = ''\n",
    "    df['sema_diff'] = ''\n",
    "    df['lema_diff'] = ''\n",
    "\n",
    "    df['top_diff'] = df['candle_max_val'] - df['tick_act']\n",
    "    df['bottom_diff'] = df['tick_act'] - df['candle_min_val'] \n",
    "    \n",
    "    # RSI -----------------------------\n",
    "    df['diff'] = df['tick_avg'].diff()\n",
    "    df['gain'] = 0\n",
    "    df['loss'] = 0\n",
    "    df['gain'].loc[df['diff'] > 0] = abs(df['diff'])\n",
    "    df['loss'].loc[df['diff'] < 0] = abs(df['diff'])\n",
    "    df['avg_gain'] = df['gain'].rolling(window=data['rsi_window']).mean()\n",
    "    df['avg_loss'] = df['loss'].rolling(window=data['rsi_window']).mean()\n",
    "    df['rs'] = df['avg_gain']/df['avg_loss']\n",
    "    df['rs'] = df['rs'].where(df['rs'] <= data['rs_max'], data['rs_max']) \n",
    "    df['rsi'] = 100 - (100 / (df['rs'] + 1))\n",
    "\n",
    "    # Simple Moving Averages ------------------\n",
    "    df['ssma'] = df['tick_avg'].rolling(window=data['sma_len']).mean()\n",
    "    df['ssma_diff'] = df['ssma'].diff()\n",
    "    df['lsma'] = df['tick_avg'].rolling(window=data['lma_len']).mean()\n",
    "    df['lsma_diff'] = df['lsma'].diff()\n",
    "    df['sma_diff'] = df['ssma'] - df['lsma']\n",
    "\n",
    "    df['max_tick'] = df['tick_avg'].rolling(window=data['sma_len']).max()\n",
    "    df['min_tick'] = df['tick_avg'].rolling(window=data['sma_len']).min()\n",
    "\n",
    "    df['max_gap'] = df['max_tick'] -  df['tick_avg']\n",
    "    df['min_gap'] = df['min_tick'] - df['tick_avg']\n",
    "\n",
    "    print(\"Emas creation...\")\n",
    "    # Emas ----------------\n",
    "    df['sema'] = df['tick_avg'].rolling(window=data['sma_len']).progress_apply(roll_ma)\n",
    "    df['lema'] = df['tick_avg'].rolling(window=data['lma_len']).progress_apply(roll_ma)\n",
    "\n",
    "    df['sema_diff'] = df['sema'].diff()\n",
    "    df['lema_diff'] = df['lema'].diff()\n",
    "\n",
    "    df['ema_diff'] = df['sema'] - df['lema']\n",
    "\n",
    "  \n",
    "    print(\"slope creation...\")\n",
    "    # Slopes -----------------------------\n",
    "    df['small_sema_slope'] = df['sema'].rolling(window=data['sma_len']).progress_apply(get_slope)\n",
    "    df['long_sema_slope'] = df['sema'].rolling(window=data['lma_len']).progress_apply(get_slope)\n",
    "\n",
    "    df['slope_diff'] = df['small_sema_slope'] - df['long_sema_slope']\n",
    "\n",
    "    print('Direction identification...')\n",
    "    df = df.round(5)\n",
    "\n",
    "    # Direction -------------------------\n",
    "    df['direction'] = 'same'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    # Remove NaNs ------------------------\n",
    "    del df['gain']\n",
    "    del df['loss']\n",
    "    \n",
    "    del df['candle_max_val']\n",
    "    del df['candle_min_val']    \n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(f'Total records : {len(df)}')\n",
    "    \n",
    "\n",
    "    if data['write_to_csv']:        \n",
    "        df.to_csv(target_file_path, index = False)\n",
    "    #winsound.PlaySound('C:\\\\Windows\\\\Media\\\\tada.wav', winsound.SND_ASYNC)\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'direction')    \n",
    "    \n",
    "    print('Avg Direction -------------------------')\n",
    "    diff_col = 'tick_avg'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'same')    \n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'increase')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'decrease')\n",
    "\n",
    "    print('\\n')\n",
    "    df['tick_act_direction'] = df['act_direction']\n",
    "    del df['act_direction']    \n",
    "\n",
    "    print('Act Direction -------------------------')\n",
    "    diff_col = 'tick_act'\n",
    "\n",
    "    df['act_direction'] = 'same'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] >= data['pip_diff']] = 'increase'\n",
    "    df['act_direction'].loc[df[diff_col].shift(-1) - df[diff_col] <= -data['pip_diff']] = 'decrease'\n",
    "\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'same')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'increase')\n",
    "    print_custom_value_counts(df = df, target_column = 'act_direction', filter_column = 'direction', filter_value = 'decrease')\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    #del df['act_direction']\n",
    "    print(f'-----------------------------------{year}--------------------------------------')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['number_of_ticks']   = 300\n",
    "data['rsi_window']        = 14\n",
    "data['sma_len']           = 5\n",
    "data['lma_len']           = 10\n",
    "data['pip_diff']          = 0.00012\n",
    "\n",
    "\n",
    "#data['input_rows']        = 1_000_000\n",
    "data['input_rows']        = None\n",
    "\n",
    "data['write_to_csv'] = True\n",
    "\n",
    "#train_files = [2020]\n",
    "train_files = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------2003--------------------------------------\n",
      "source_file_path : data/yearly_tick_data/2003.csv\n",
      "chunk_file_path : data/yearly_tick_data\\chunk_2003.csv\n",
      "target_file_path : data/yearly_tick_data\\tab_2003.csv\n",
      "Total input recs : 6993511\n",
      "Data manipulation...\n",
      "Extracing weekday and hour...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████████████████▍                          | 4613095/6993511 [00:52<00:28, 83331.18it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for year in train_files:\n",
    "    run_data_prep(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
